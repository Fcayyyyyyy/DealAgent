{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cF-bBFwT_VRv",
        "outputId": "dac77195-b2f1-4df3-c0c2-4da7f7a0f05a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.91.0)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Collecting feedparser\n",
            "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.13)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.33.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.52.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (8.5.0)\n",
            "Collecting sgmllib3k (from feedparser)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m106.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sgmllib3k\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=59aca39bde3c39e190fb3695c5f94290e134a5bfe8095eebf17b33d3f409930b\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/25/2a/105d6a15df6914f4d15047691c6c28f9052cc1173e40285d03\n",
            "Successfully built sgmllib3k\n",
            "Installing collected packages: sgmllib3k, python-dotenv, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, feedparser, faiss-cpu, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed faiss-cpu-1.11.0 feedparser-6.0.11 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 python-dotenv-1.1.1 sgmllib3k-1.0.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#  STEP 1: Install all required packages\n",
        "!pip install openai gradio sentence-transformers faiss-cpu plotly feedparser scikit-learn python-dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Open AI Key is downloaded\n",
        "#upload env key from shared folder\n",
        "# STEP: Download .env from shared folder using Google Drive File ID\n",
        "!pip install -q gdown python-dotenv\n",
        "\n",
        "import gdown\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# 🔁 Replace this with your real file ID from the .env link\n",
        "env_file_id = \"1McGLUCSCk0E1NzFedeqlLPaiscSoYAKJ\"  # e.g. \"1ABCDEF123456XYZ\"\n",
        "env_path = \"/content/.env\"\n",
        "\n",
        "# Download the file\n",
        "gdown.download(f\"https://drive.google.com/uc?id={env_file_id}\", env_path, quiet=False)\n",
        "\n",
        "# Load and test\n",
        "load_dotenv(env_path)\n",
        "key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "if key:\n",
        "    print(\"✅ OPENAI_API_KEY loaded successfully.\")\n",
        "else:\n",
        "    print(\"❌ OPENAI_API_KEY not found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNjDefaxEFI4",
        "outputId": "80f3c4e8-9db1-425c-ae70-099bc67612d9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1McGLUCSCk0E1NzFedeqlLPaiscSoYAKJ\n",
            "To: /content/.env\n",
            "100%|██████████| 179/179 [00:00<00:00, 605kB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ OPENAI_API_KEY loaded successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load API and test key access  For testing only, can be deleted\n",
        "\n",
        "# Load environment and test OpenAI GPT access\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "\n",
        "# Load the .env file containing your API key\n",
        "load_dotenv()\n",
        "\n",
        "# Create OpenAI client using the loaded key\n",
        "client = OpenAI()\n",
        "\n",
        "# Test a basic prompt to verify GPT-3.5-turbo is accessible\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are an AI assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Is $49 a good deal for Sony headphones?\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Print GPT response to verify setup\n",
        "print(response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sy66n6sWEfld",
        "outputId": "7be64c44-41ac-4efc-ad9b-cb826778c4b3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The value of $49 for Sony headphones would depend on the model and features of the headphones. Generally speaking, Sony is a reputable brand known for producing quality audio products. To determine if $49 is a good deal, I would recommend checking the specifications, reviews, and comparing prices with similar headphones from other brands.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 📰 STEP 3: Create the RSS sources file, it will provide RSS Feeds sources, from where deals will be hunted\n",
        "with open(\"rss_sources.txt\", \"w\") as f:\n",
        "    f.write(\"\"\"https://slickdeals.net/newsearch.php?searcharea=deals&rss=1&forumchoice[]=9\n",
        "https://slickdeals.net/newsearch.php?searcharea=deals&rss=1&forumchoice[]=4\n",
        "https://slickdeals.net/newsearch.php?searcharea=deals&rss=1&forumchoice[]=30\n",
        "https://www.techbargains.com/rss.xml\n",
        "https://bensbargains.com/c/computers/\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "id": "0FibpwXlLsWe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  STEP 4: Create fetch_deals.py to fetch and parse deals from RSS\n",
        "\n",
        "with open(\"fetch_deals.py\", \"w\") as f:\n",
        "    f.write(\"\"\"\n",
        "import feedparser\n",
        "import random\n",
        "import re\n",
        "\n",
        "def load_rss_sources(file_path=\"rss_sources.txt\"):\n",
        "    try:\n",
        "        with open(file_path, \"r\") as f:\n",
        "            return [line.strip() for line in f.readlines() if line.strip()]\n",
        "    except FileNotFoundError:\n",
        "        print(\"rss_sources.txt not found.\")\n",
        "        return []\n",
        "\n",
        "def extract_price(text):\n",
        "    match = re.search(r\"\\$\\s?(\\d+(\\.\\d{1,2})?)\", text)\n",
        "    if match:\n",
        "        return float(match.group(1))\n",
        "    return round(random.uniform(5, 50), 2)  # fallback dummy price\n",
        "\n",
        "def fetch_deals_rss():\n",
        "    sources = load_rss_sources()\n",
        "    all_deals = []\n",
        "\n",
        "    for url in sources:\n",
        "        feed = feedparser.parse(url)\n",
        "        for entry in feed.entries:\n",
        "            title = entry.title\n",
        "            link = entry.link\n",
        "            price = extract_price(title + \" \" + entry.get(\"summary\", \"\"))\n",
        "            all_deals.append({\"title\": title, \"price\": price, \"link\": link})\n",
        "\n",
        "    return all_deals[:20]  # return top 20 parsed entries\n",
        "\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "3Pwg8tdxMVHE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  STEP 5: Create gpt_evaluator.py for GPT-based deal evaluation\n",
        "# gpt_evaluator.py\n",
        "\n",
        "with open(\"gpt_evaluator.py\", \"w\") as f:\n",
        "    f.write(\"\"\"\n",
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "def gpt_evaluate_deal(title, price):\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful shopping assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": f\"Evaluate this deal: '{title}' priced at ${price}. Is it a good value?\"}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "    except Exception as e:\n",
        "        return f\"GPT error: {str(e)}\"\n",
        "\n",
        "def gpt_answer(question, context):\n",
        "    try:\n",
        "        prompt = f\\\"\\\"\\\"You are a deal expert. Based on the following deals:\n",
        "{context}\n",
        "\n",
        "Answer this user question:\n",
        "{question}\n",
        "\\\"\\\"\\\"\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful deal assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "    except Exception as e:\n",
        "        return f\"GPT error: {str(e)}\"\n",
        "\"\"\")\n",
        "\n"
      ],
      "metadata": {
        "id": "PhxALnk1MihE"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This module estimates a \"fair market price\" using a Transformer-based text embedding and a pre-trained Random Forest model.\n",
        "\n",
        "#  STEP 6: Create price_model.py for ML-based price estimation\n",
        "with open(\"price_model.py\", \"w\") as f:\n",
        "    f.write(\"\"\"\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import numpy as np\n",
        "\n",
        "# Load lightweight transformer model\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Dummy training data (titles vs prices)\n",
        "# In real use, replace with a trained model\n",
        "X_train = model.encode([\n",
        "    \"Wireless Mouse\",\n",
        "    \"Gaming Laptop\",\n",
        "    \"Bluetooth Speaker\",\n",
        "    \"USB-C Cable\",\n",
        "    \"Smartphone\",\n",
        "    \"Noise Cancelling Headphones\",\n",
        "    \"External SSD\",\n",
        "    \"Office Chair\",\n",
        "    \"Mechanical Keyboard\",\n",
        "    \"4K Monitor\"\n",
        "])\n",
        "\n",
        "y_train = [15, 900, 45, 10, 500, 180, 100, 120, 70, 300]\n",
        "\n",
        "# Train model\n",
        "regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "def predict_value(title):\n",
        "    embedding = model.encode([title])\n",
        "    prediction = regressor.predict(embedding)\n",
        "    return float(prediction[0])\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "id": "XWoFU_UPMn6v"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This module sets up a FAISS vector index to enable semantic search over deals, and uses GPT to answer user questions based on matched deals.\n",
        "#step 7\n",
        "rag_faiss_code = '''\n",
        "# rag_faiss.py\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "from gpt_evaluator import gpt_answer\n",
        "from shared_data import get_top_deals\n",
        "\n",
        "# Load sentence transformer model once\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "def build_top5_index():\n",
        "    \"\"\"\n",
        "    Builds a FAISS index using only the current Top 5 deals.\n",
        "    \"\"\"\n",
        "    top_deals = get_top_deals()\n",
        "    if not top_deals:\n",
        "        return None, None\n",
        "\n",
        "    texts = [f\"{deal['title']}. {deal['description']}\" for deal in top_deals]\n",
        "    embeddings = model.encode(texts, convert_to_numpy=True)\n",
        "\n",
        "    dim = embeddings.shape[1]\n",
        "    index = faiss.IndexFlatL2(dim)\n",
        "    index.add(embeddings)\n",
        "\n",
        "    return index, texts\n",
        "\n",
        "def query_top5_rag(question, k=2):\n",
        "    \"\"\"\n",
        "    Queries the Top 5 deals only using FAISS and returns a GPT-generated answer.\n",
        "    \"\"\"\n",
        "    index, texts = build_top5_index()\n",
        "    if index is None:\n",
        "        return \"⚠️ No top deals available to answer your question.\"\n",
        "\n",
        "    question_embedding = model.encode([question])\n",
        "    D, I = index.search(np.array(question_embedding), k)\n",
        "\n",
        "    relevant_chunks = [texts[i] for i in I[0] if i < len(texts)]\n",
        "    context = \"\\\\n\".join(relevant_chunks)\n",
        "\n",
        "    return gpt_answer(question, context)\n",
        "'''\n",
        "\n",
        "# Write to file\n",
        "with open(\"rag_faiss.py\", \"w\") as f:\n",
        "    f.write(rag_faiss_code)\n",
        "\n",
        "print(\"✅ rag_faiss.py file created.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "SorpHubOM2r1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83b6391b-fc3a-4e7d-e306-8e9c5738ed80"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ rag_faiss.py file created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This module performs 3D clustering of deal titles using TSNE and Plotly, and saves the plot as an HTML file.\n",
        "#  STEP 8: Create visualizer.py for 3D TSNE clustering of deal titles\n",
        "# STEP 8: Create visualizer.py for 3D TSNE clustering of deal titles\n",
        "with open(\"visualizer.py\", \"w\") as f:\n",
        "    f.write(\"\"\"\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.manifold import TSNE\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "def generate_3d_plot(deals, file_path=\"deal_clusters_plot.html\"):\n",
        "    if not deals or len(deals) < 2:\n",
        "        raise ValueError(\"⚠️ At least 2 deals are required to generate a 3D plot.\")\n",
        "\n",
        "    titles = [deal['title'] for deal in deals[:20]]\n",
        "    prices = [deal['price'] for deal in deals[:20]]\n",
        "\n",
        "    embeddings = model.encode(titles)\n",
        "    n_samples = len(embeddings)\n",
        "    perplexity = max(2, min(30, n_samples - 1))  # Dynamically safe\n",
        "\n",
        "    tsne = TSNE(n_components=3, perplexity=perplexity, random_state=42)\n",
        "    tsne_3d = tsne.fit_transform(embeddings)\n",
        "\n",
        "    fig = px.scatter_3d(\n",
        "        x=tsne_3d[:, 0],\n",
        "        y=tsne_3d[:, 1],\n",
        "        z=tsne_3d[:, 2],\n",
        "        color=prices,\n",
        "        hover_name=titles,\n",
        "        labels={\"color\": \"Price ($)\"},\n",
        "        title=\"3D Semantic Clustering of Deal Titles\"\n",
        "    )\n",
        "    fig.update_traces(marker=dict(size=6))\n",
        "    fig.update_layout(height=700, width=1000)\n",
        "\n",
        "    fig.write_html(file_path)\n",
        "    return file_path\n",
        "\"\"\")\n",
        "\n"
      ],
      "metadata": {
        "id": "g1Lfob--Njt-"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step 9: Create shared_data.py for sharing data among different tabs, within a session\n",
        "# Create shared_data.py to store and retrieve shared state\n",
        "with open(\"shared_data.py\", \"w\") as f:\n",
        "    f.write(\"\"\"\n",
        "top_deals = []\n",
        "\n",
        "def set_top_deals(deals):\n",
        "    global top_deals\n",
        "    top_deals = deals\n",
        "\n",
        "def get_top_deals():\n",
        "    return top_deals\n",
        "\n",
        "def append_log(message):\n",
        "    with open(\"logs.txt\", \"a\", encoding=\"utf-8\") as f:\n",
        "        f.write(message + \"\\\\n\")\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "id": "7KEYTeKFqDvo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Working OK, Needs Better Formatting\n",
        "code = '''\n",
        "import gradio as gr\n",
        "from fetch_deals import fetch_deals_rss\n",
        "from gpt_evaluator import gpt_evaluate_deal\n",
        "from price_model import predict_value\n",
        "from rag_faiss import query_top5_rag\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.manifold import TSNE\n",
        "from shared_data import set_top_deals, get_top_deals, append_log\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "project_path = \"/content\"\n",
        "\n",
        "def format_deals_as_html(deals):\n",
        "    html = \"\"\"\n",
        "    <style>\n",
        "        .deal-box {\n",
        "            border: 1px solid #ddd;\n",
        "            border-radius: 10px;\n",
        "            padding: 15px;\n",
        "            margin-bottom: 20px;\n",
        "            background-color: #fdfdfd;\n",
        "            box-shadow: 1px 1px 6px rgba(0,0,0,0.06);\n",
        "        }\n",
        "        .deal-title {\n",
        "            font-weight: bold;\n",
        "            font-size: 18px;\n",
        "            margin-bottom: 5px;\n",
        "        }\n",
        "        .deal-meta {\n",
        "            font-size: 14px;\n",
        "            color: #333;\n",
        "        }\n",
        "        .deal-meta span {\n",
        "            display: inline-block;\n",
        "            margin-right: 10px;\n",
        "        }\n",
        "        .deal-eval {\n",
        "            margin-top: 10px;\n",
        "            font-style: italic;\n",
        "            color: #333;\n",
        "        }\n",
        "        .deal-link a {\n",
        "            display: inline-block;\n",
        "            margin-top: 10px;\n",
        "            color: #1a73e8;\n",
        "            text-decoration: none;\n",
        "            font-weight: bold;\n",
        "        }\n",
        "    </style>\n",
        "    \"\"\"\n",
        "    for d in deals:\n",
        "        safe_link = d['link'] if d['link'].startswith(\"http\") else \"#\"\n",
        "        html += f\"\"\"\n",
        "        <div class=\"deal-box\">\n",
        "            <div class=\"deal-title\">{d['title']}</div>\n",
        "            <div class=\"deal-meta\">\n",
        "                <span><strong>Price:</strong> ${d['price']:.2f}</span>\n",
        "                <span><strong>Estimated Value:</strong> ${d['est_value']:.2f}</span>\n",
        "                <span><strong>Discount:</strong> {d['discount']:.2f}%</span>\n",
        "            </div>\n",
        "            <div class=\"deal-eval\">{d['gpt_response']}</div>\n",
        "            <div class=\"deal-link\"><a href=\"{safe_link}\" target=\"_blank\">🔗 View Deal</a></div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "    return html\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def show_top_deals():\n",
        "    raw_deals = fetch_deals_rss()\n",
        "\n",
        "    top_deals = []\n",
        "    for deal in raw_deals[:5]:\n",
        "        title = deal['title']\n",
        "        price = deal['price']\n",
        "        link = deal['link']\n",
        "        gpt_response = gpt_evaluate_deal(title, price)\n",
        "        est_value = predict_value(title)\n",
        "        discount = round((1 - price / est_value) * 100, 2)\n",
        "\n",
        "        top_deals.append({\n",
        "            'title': title,\n",
        "            'price': price,\n",
        "            'link': link,\n",
        "            'gpt_response': gpt_response,\n",
        "            'est_value': est_value,\n",
        "            'discount': discount,\n",
        "            'description': f\"{title} at ${price:.2f}\"  # ✅ required by RAG\n",
        "        })\n",
        "\n",
        "        append_log(f\"[{datetime.now()}] GPT evaluated deal: {title} (${price}) → {gpt_response}\")\n",
        "\n",
        "    # ✅ Only set the processed Top 5 (with description)\n",
        "    set_top_deals(top_deals)\n",
        "\n",
        "    return format_deals_as_html(top_deals)\n",
        "\n",
        "\n",
        "\n",
        "def rag_answer(query):\n",
        "    response = query_top5_rag(query)\n",
        "    append_log(f\"[{datetime.now()}] RAG Q: {query} → {response}\")\n",
        "    return response\n",
        "\n",
        "from fetch_deals import fetch_deals_rss  # at the top if not already\n",
        "\n",
        "def generate_visualization():\n",
        "    deals = fetch_deals_rss()[:20]  # Fetch 20 fresh deals for plotting\n",
        "    if not deals or len(deals) < 3:\n",
        "        return \"⚠️ Need at least 3 deals to generate a 3D plot.\"\n",
        "\n",
        "    titles = [deal['title'] for deal in deals]\n",
        "    prices = [deal['price'] for deal in deals]\n",
        "    embeddings = model.encode(titles)\n",
        "\n",
        "    n_samples = len(embeddings)\n",
        "    perplexity = max(2, min(30, n_samples - 1))  # ✅ Dynamic and safe\n",
        "\n",
        "    try:\n",
        "        tsne = TSNE(n_components=3, perplexity=perplexity, random_state=42)\n",
        "        tsne_3d = tsne.fit_transform(embeddings)\n",
        "\n",
        "        fig = px.scatter_3d(\n",
        "            x=tsne_3d[:, 0],\n",
        "            y=tsne_3d[:, 1],\n",
        "            z=tsne_3d[:, 2],\n",
        "            color=prices,\n",
        "            hover_name=titles,\n",
        "            labels={\"color\": \"Price ($)\"},\n",
        "            title=\"3D Semantic Clustering of Deal Titles\"\n",
        "        )\n",
        "        fig.update_layout(height=700, width=1000)\n",
        "        fig.update_traces(marker=dict(size=6))\n",
        "\n",
        "        file_path = os.path.join(project_path, \"deal_clusters_plot.html\")\n",
        "        fig.write_html(file_path)\n",
        "        append_log(f\"[{datetime.now()}] 📊 3D plot generated.\")\n",
        "        return file_path\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Plot error: {str(e)}\"\n",
        "\n",
        "\n",
        "def read_logs():\n",
        "    log_path = os.path.join(project_path, \"logs.txt\")\n",
        "    if os.path.exists(log_path):\n",
        "        with open(log_path, \"r\") as f:\n",
        "            return f.read()\n",
        "    return \"No logs found.\"\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## 🤖 AI Deal Hunter v1.1\")\n",
        "\n",
        "    with gr.Tab(\"🔍 Top 5 Deal Evaluations\"):\n",
        "        deal_output = gr.HTML()\n",
        "        gr.Button(\"Fetch Deals\").click(fn=show_top_deals, outputs=deal_output)\n",
        "\n",
        "    with gr.Tab(\"🧠 Ask the Deal Expert (RAG)\"):\n",
        "        question = gr.Textbox(label=\"Ask your question\")\n",
        "        answer = gr.Textbox(label=\"Expert Answer\")\n",
        "        gr.Button(\"Submit\").click(fn=rag_answer, inputs=question, outputs=answer)\n",
        "\n",
        "    with gr.Tab(\"📈 Download 3D Visualization\"):\n",
        "        file_output = gr.File()\n",
        "        gr.Button(\"Generate & Download Plot\").click(fn=generate_visualization, outputs=file_output)\n",
        "\n",
        "    with gr.Tab(\"📜 Logs\"):\n",
        "        logs_text = gr.Textbox(lines=20, label=\"Logs\")\n",
        "        gr.Button(\"Refresh Logs\").click(fn=read_logs, outputs=logs_text)\n",
        "\n",
        "demo.launch(share=True)\n",
        "'''\n",
        "\n",
        "# Write to file\n",
        "with open(\"app_with_logs.py\", \"w\") as f:\n",
        "    f.write(code)\n"
      ],
      "metadata": {
        "id": "PwwLwEO6OYEt"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the App Now\n",
        "!python app_with_logs.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMcR6X0vOci1",
        "outputId": "f9c381b6-1562-4bfd-a430-61593c7d4e3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-26 14:16:57.369522: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750947417.393118   16869 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750947417.400128   16869 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-26 14:16:57.422927: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* Running on public URL: https://504bcf84ba11a7ffad.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from shared_data import get_top_deals\n",
        "deals = get_top_deals()\n",
        "print(deals)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHZS-ei_-UXP",
        "outputId": "057efe45-f004-4bb5-a11d-a952d9cda6c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "title = \"Logitech Wireless Mouse\"\n",
        "price = 19.99\n",
        "gpt_response = \"Good deal for casual users\"\n",
        "est_value = 29.99\n",
        "discount = round((1 - price / est_value) * 100, 2)\n",
        "link = \"https://example.com/mouse\"\n",
        "\n",
        "# Safe string formatting\n",
        "line = (\n",
        "    f\"Title: {title}\\n\"\n",
        "    f\"Price: ${price}\\n\"\n",
        "    f\"GPT Evaluation: {gpt_response}\\n\"\n",
        "    f\"Estimated Value: ${est_value:.2f}\\n\"\n",
        "    f\"Discount: {discount:.2f}%\\n\"\n",
        "    f\"Link: {link if link.startswith('http') else '#'}\\n\"\n",
        "    \"----------------------------------------\"\n",
        ")\n",
        "\n",
        "line = (\n",
        "    f\"Title: {title}\\n\"\n",
        "    f\"Price: ${price}\\n\"\n",
        "    f\"GPT Evaluation: {gpt_response}\\n\"\n",
        "    f\"Estimated Value: ${est_value:.2f}\\n\"\n",
        "    f\"Discount: {discount:.2f}%\\n\"\n",
        "    f\"Link: {link if link.startswith('http') else '#'}\\n\"\n",
        "    \"----------------------------------------\"\n",
        ")\n",
        "print(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K16XuThzj55n",
        "outputId": "46e48acd-feb2-447c-8c98-751888dfaa78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: Logitech Wireless Mouse\n",
            "Price: $19.99\n",
            "GPT Evaluation: Good deal for casual users\n",
            "Estimated Value: $29.99\n",
            "Discount: 33.34%\n",
            "Link: https://example.com/mouse\n",
            "----------------------------------------\n"
          ]
        }
      ]
    }
  ]
}
